{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sdtDsu1Y0EqL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.attention.flex_attention import flex_attention, create_block_mask\n",
        "import triton\n",
        "import triton.language as tl\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "torch.manual_seed(69)\n",
        "torch.set_printoptions(profile=\"short\", sci_mode=False, linewidth=100000)\n",
        "torch.set_float32_matmul_precision('high')\n",
        "# this script is configured to run on a RTX 3060 12GB GPU. you'll want to adjust the model sizes and batch sizes for other devices\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "plt.rcParams['figure.figsize'] = [8, 6]\n",
        "plt.rcParams['figure.dpi'] = 50\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['xtick.minor.visible'] = True\n",
        "plt.rcParams['ytick.minor.visible'] = True\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANr5dn7W0EqR",
        "outputId": "a00cbe8d-e1c6-454b-b552-4ffd17ce17e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  39526018\n"
          ]
        }
      ],
      "source": [
        "# we use this 40mb file of concatenated anime subtitles as our dataset\n",
        "# just the right size for toy experiments like this I think\n",
        "with open('animesubs.txt', 'r', encoding='latin') as f:\n",
        "    text = f.read()\n",
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pANiObIZ0EqU",
        "outputId": "98f70469-1c89-4341-89e8-c142a14331b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Open your mind. Open your mind.\n",
            "\n",
            "Far beyond the deep blue Earth, you and I shall meet...\n",
            "\n",
            "AH! MY GODDESS\n",
            "\n",
            "A snow-white feather comes fluttering down, swaying gently in the air.\n",
            "\n",
            "Without holding back, I want to envelope you, my one and only love.\n",
            "\n",
            "I know I have the power to protect the one I love, right here in my hands.\n",
            "\n",
            "Open your mind. Just as I've always dreamed.\n",
            "\n",
            "Let the wind carry off your hopes, faraway.\n",
            "\n",
            "I have wings nobody can see. Look, you have them, too.\n",
            "\n",
            "They'll take us to where we ca\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WvM5h6_i3KsM"
      },
      "outputs": [],
      "source": [
        "# remove japanese characters\n",
        "text = ''.join(filter(lambda character:ord(character) < 0x3000, text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SOcWJM0EqW",
        "outputId": "a82a4da8-a8ed-47bf-cfb5-2e4c59dee2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique characters: 86 \n",
            " !'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz|Â”\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"unique characters:\", vocab_size, ''.join(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yobmmaeK0EqX",
        "outputId": "26669f38-4b26-4b53-f642-ee7543e7c578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '(': 4, ')': 5, '*': 6, '+': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, ';': 23, '<': 24, '=': 25, '>': 26, '?': 27, '@': 28, 'A': 29, 'B': 30, 'C': 31, 'D': 32, 'E': 33, 'F': 34, 'G': 35, 'H': 36, 'I': 37, 'J': 38, 'K': 39, 'L': 40, 'M': 41, 'N': 42, 'O': 43, 'P': 44, 'Q': 45, 'R': 46, 'S': 47, 'T': 48, 'U': 49, 'V': 50, 'W': 51, 'X': 52, 'Y': 53, 'Z': 54, '[': 55, ']': 56, '_': 57, 'a': 58, 'b': 59, 'c': 60, 'd': 61, 'e': 62, 'f': 63, 'g': 64, 'h': 65, 'i': 66, 'j': 67, 'k': 68, 'l': 69, 'm': 70, 'n': 71, 'o': 72, 'p': 73, 'q': 74, 'r': 75, 's': 76, 't': 77, 'u': 78, 'v': 79, 'w': 80, 'x': 81, 'y': 82, 'z': 83, '|': 84, '\\x94': 85, '': 86}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: '*', 7: '+', 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: ';', 24: '<', 25: '=', 26: '>', 27: '?', 28: '@', 29: 'A', 30: 'B', 31: 'C', 32: 'D', 33: 'E', 34: 'F', 35: 'G', 36: 'H', 37: 'I', 38: 'J', 39: 'K', 40: 'L', 41: 'M', 42: 'N', 43: 'O', 44: 'P', 45: 'Q', 46: 'R', 47: 'S', 48: 'T', 49: 'U', 50: 'V', 51: 'W', 52: 'X', 53: 'Y', 54: 'Z', 55: '[', 56: ']', 57: '_', 58: 'a', 59: 'b', 60: 'c', 61: 'd', 62: 'e', 63: 'f', 64: 'g', 65: 'h', 66: 'i', 67: 'j', 68: 'k', 69: 'l', 70: 'm', 71: 'n', 72: 'o', 73: 'p', 74: 'q', 75: 'r', 76: 's', 77: 't', 78: 'u', 79: 'v', 80: 'w', 81: 'x', 82: 'y', 83: 'z', 84: '|', 85: '\\x94', 86: ''}\n",
            "encoded: [43, 73, 62, 71, 1, 82, 72, 78, 75, 1, 70, 66, 71, 61, 10, 1, 43, 73, 62, 71]\n",
            "decoded: Open your mind. Open\n",
            "vocab size: 87\n"
          ]
        }
      ],
      "source": [
        "# yes, all language models will be character level, which isn't ideal but it's good for simplicity\n",
        "# very simple tokenizer\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "# add special token for padding\n",
        "stoi[''] = len(stoi)\n",
        "itos[len(itos)] = ''\n",
        "print(stoi)\n",
        "print(itos)\n",
        "encode = lambda s: [stoi[ch] for ch in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(\"encoded:\", encode(text[:20]))\n",
        "print(\"decoded:\", decode(encode(text[:20])))\n",
        "vocab_size = len(itos)\n",
        "print(\"vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pnf9KfP0EqY",
        "outputId": "ff581168-335a-4f0f-efeb-0d4bd5b225ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([39526018])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.int64)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ2fY1pR0EqY",
        "outputId": "5eb599e0-fb79-4cdb-c4b9-52a781d67151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([43, 73, 62, 71,  1, 82, 72, 78, 75,  1, 70, 66, 71, 61, 10,  1, 43, 73, 62, 71,  1, 82, 72, 78, 75,  1, 70, 66, 71, 61, 10,  0,  0, 34, 58, 75,  1, 59, 62, 82, 72, 71, 61,  1, 77, 65, 62,  1, 61, 62, 62, 73,  1, 59, 69, 78, 62,  1, 33, 58, 75, 77, 65,  8,  1, 82, 72, 78,  1, 58, 71, 61,  1, 37,  1, 76, 65, 58, 69, 69,  1, 70, 62, 62, 77, 10, 10, 10,  0,  0, 29, 36,  2,  1, 41, 53,  1, 35, 43, 32])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIaYesPh0Eqa",
        "outputId": "caa27cbb-5ae3-4406-8194-646264d4ba99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([39130757]) torch.Size([395261])\n"
          ]
        }
      ],
      "source": [
        "n = int(len(data) * 0.99)\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(train_data.shape, val_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bFhizcI0Eqa",
        "outputId": "c93a4d43-6fb2-4de7-aefc-8fed47e4a861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([43, 73, 62, 71,  1, 82, 72, 78, 75])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq_len = 8\n",
        "train_data[:seq_len+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skFCPvQC0Eqc",
        "outputId": "08990c5b-88af-4a51-ce37-3c59989d6d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([2, 64])\n",
            "tensor([[64,  1, 72, 78, 75,  1, 66, 71, 77, 62, 75, 71, 76, 65, 66, 73, 76, 10,  0,  0, 48, 65, 62,  1, 71, 66, 64, 65, 77,  1, 37, 66, 61, 58,  1, 64, 72, 77,  1, 77, 65, 62,  1, 75, 62, 76, 78, 69, 77, 76,  1, 72, 63,  1, 77, 65, 62,  1, 62, 81, 58, 70, 66, 71],\n",
            "        [62, 70,  2,  0,  0, 37, 77,  1, 69, 72, 72, 68, 76,  1, 69, 66, 68, 62,  1, 80, 62,  1, 77, 72, 72, 68,  1, 60, 58, 75, 62,  1, 72, 63,  1, 77, 65, 62, 70, 10,  0,  0, 48, 65, 72, 76, 62,  1, 64, 78, 82, 76,  1, 80, 62, 75, 62,  1, 66, 71, 60, 75, 62, 61]], device='cuda:0')\n",
            "targets:\n",
            "torch.Size([2, 64])\n",
            "tensor([[ 1, 72, 78, 75,  1, 66, 71, 77, 62, 75, 71, 76, 65, 66, 73, 76, 10,  0,  0, 48, 65, 62,  1, 71, 66, 64, 65, 77,  1, 37, 66, 61, 58,  1, 64, 72, 77,  1, 77, 65, 62,  1, 75, 62, 76, 78, 69, 77, 76,  1, 72, 63,  1, 77, 65, 62,  1, 62, 81, 58, 70, 66, 71, 58],\n",
            "        [70,  2,  0,  0, 37, 77,  1, 69, 72, 72, 68, 76,  1, 69, 66, 68, 62,  1, 80, 62,  1, 77, 72, 72, 68,  1, 60, 58, 75, 62,  1, 72, 63,  1, 77, 65, 62, 70, 10,  0,  0, 48, 65, 72, 76, 62,  1, 64, 78, 82, 76,  1, 80, 62, 75, 62,  1, 66, 71, 60, 75, 62, 61, 66]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "def get_batch(split, seq_len, batch_size=4):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    # targets are just inputs shifted by 1\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - seq_len, (batch_size,))\n",
        "    x = torch.stack([data[i:i+seq_len] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+seq_len+1] for i in ix])\n",
        "    return x.to(device), y.to(device)\n",
        "\n",
        "xb, yb = get_batch('train', 64, 2)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "327680000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make all steps, sequence lengths, and batch size the same\n",
        "total_steps = 5000\n",
        "seq_len = 256\n",
        "batch_size = 256 # these are small models so we can use large batch sizes to fully utilize the GPU\n",
        "# should cover around 2x the dataset\n",
        "total_steps * seq_len * batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, optimizer, seq_len, batch_size, total_steps, val_steps=10, val_interval=50):\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "    # live plot\n",
        "    fig, ax = plt.subplots()\n",
        "    dh = display.display(fig, display_id=True)\n",
        "    for steps in (bar := tqdm(range(total_steps))):  # increase number of steps for good results...\n",
        "        # sample a batch of data\n",
        "        xb, yb = get_batch('train', seq_len=seq_len, batch_size=batch_size)\n",
        "\n",
        "        # evaluate the loss\n",
        "        logits, loss = model(xb, yb)\n",
        "\n",
        "        # backprop\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bar.set_description(f\"loss: {loss.item():.2f}, val loss: {val_losses[-1] if val_losses else 0:.2f}\")\n",
        "        losses.append(loss.item())\n",
        "        if steps % val_interval == 0:\n",
        "            # Calculate validation loss\n",
        "            with torch.no_grad():\n",
        "                val_loss = 0\n",
        "                for _ in range(val_steps):\n",
        "                    xb, yb = get_batch('val', seq_len=seq_len, batch_size=batch_size)\n",
        "                    _, loss = model(xb, yb)\n",
        "                    val_loss += loss.item()\n",
        "                val_loss /= val_steps\n",
        "                val_losses.append(val_loss)\n",
        "            ax.clear()\n",
        "            ax.plot(losses, color='blue', label='train loss', alpha=0.7)\n",
        "            ax.plot(range(0, len(losses), val_interval), val_losses, color='red', label='val loss', alpha=0.7)\n",
        "            ax.set_ylim(1, 4)\n",
        "            ax.legend()\n",
        "            dh.update(fig)\n",
        "    print('final loss:', loss.item(), 'final val loss:', val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Measure post training perplexity on validation set\n",
        "# Create function that receives a model, context length, and PPL sequence length, and returns the perplexity\n",
        "# The PPL sequence length is the number of characters the function uses to calculate the perplexity\n",
        "# We take the logits and calculate the cross entropy loss from scratch, then exponentiate it to get the perplexity\n",
        "# not only that, but we want the models to do this in actual inference\n",
        "def perplexity(model, seq_len, ppl_seq_len, batch_size=128, val_steps=1000):\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        for _ in tqdm(range(val_steps)):\n",
        "            xb, yb = get_batch('val', seq_len=seq_len, batch_size=batch_size)\n",
        "            with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
        "                logits, _ = model(xb, yb)\n",
        "            logits = logits.reshape(batch_size, seq_len, vocab_size)\n",
        "            logits = logits[:, :ppl_seq_len]\n",
        "            yb = yb[:, :ppl_seq_len]\n",
        "            # flatten logits and targets\n",
        "            logits = logits.reshape(batch_size*ppl_seq_len, vocab_size)\n",
        "            yb = yb.reshape(batch_size*ppl_seq_len)\n",
        "            # calculate cross entropy loss from scratch\n",
        "            loss = F.cross_entropy(logits, yb)\n",
        "            val_loss += loss.item()\n",
        "        val_loss /= val_steps\n",
        "        ppl = torch.exp(torch.tensor(val_loss))\n",
        "        return ppl.item(), val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classic Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k6cA2WbrayyL"
      },
      "outputs": [],
      "source": [
        "class TransformerConfig:\n",
        "    def __init__(self, vocab_size, seq_len, embed_size, head_num, layer_num):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_len = seq_len\n",
        "        self.embed_size = embed_size\n",
        "        self.head_num = head_num\n",
        "        self.layer_num = layer_num\n",
        "\n",
        "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n",
        "    freqs = torch.outer(t, freqs)\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
        "    return freqs_cis.to(device)\n",
        "\n",
        "def apply_rotary_emb(\n",
        "    xq: torch.Tensor,\n",
        "    xk: torch.Tensor,\n",
        "    freqs_cis: torch.Tensor,\n",
        "):\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    # freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
        "    q_shape = [d if i == xq_.ndim - 2 or i == xq_.ndim - 1 else 1 for i, d in enumerate(xq_.shape)]\n",
        "    k_shape = [d if i == xq_.ndim - 2 or i == xk_.ndim - 1 else 1 for i, d in enumerate(xk_.shape)]\n",
        "    T_q = xq_.shape[-2] \n",
        "    q_freqs_cis = freqs_cis[-T_q:].view(*q_shape)\n",
        "    k_freqs_cis = freqs_cis.view(*k_shape)\n",
        "    xq_out = torch.view_as_real(xq_ * q_freqs_cis).flatten(xq.dim() - 1)\n",
        "    xk_out = torch.view_as_real(xk_ * k_freqs_cis).flatten(xq.dim() - 1)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "    \n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(config.embed_size, config.embed_size*4)\n",
        "        self.lin_2 = nn.Linear(config.embed_size*4, config.embed_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention with AliBi in parallel \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.seq_len = config.seq_len\n",
        "        self.head_num = config.head_num\n",
        "        self.head_size = config.embed_size // config.head_num\n",
        "        self.key = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.query = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.value = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.o = nn.Linear(config.embed_size, config.embed_size)\n",
        "        # block_mask for FlexAttention\n",
        "        def causal(b, h, q_idx, kv_idx):\n",
        "            causal_mask = q_idx >= kv_idx\n",
        "            return causal_mask\n",
        "        self.causal_mask = create_block_mask(causal, B=None, H=None, Q_LEN=config.seq_len, KV_LEN=config.seq_len)\n",
        "        self.freqs_cis = precompute_freqs_cis(config.embed_size//config.head_num, config.seq_len)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.seq_len, config.seq_len)))\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        B, T, C = x.shape\n",
        "        _, _, T_past, _ = kv_cache[0].shape if kv_cache is not None and kv_cache[0] is not None else (0, 0, 0, 0)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        v = self.value(x) # (B,T,C)\n",
        "\n",
        "        # Split into heads\n",
        "        q = q.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "        k = k.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "        v = v.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "\n",
        "        if kv_cache is not None:\n",
        "            k_past, v_past = kv_cache\n",
        "            if k_past is not None:\n",
        "                k = torch.cat((k_past, k), dim=2)\n",
        "                v = torch.cat((v_past, v), dim=2)\n",
        "            if k.shape[-2] > self.seq_len:\n",
        "                k = k[:, :, -self.seq_len:]\n",
        "                v = v[:, :, -self.seq_len:]\n",
        "            kv_cache = (k, v)\n",
        "        T_k = k.shape[-2]\n",
        "        q, k = apply_rotary_emb(q, k, self.freqs_cis[:T_k])\n",
        "\n",
        "        if T == self.seq_len:\n",
        "            out = flex_attention(q, k, v, block_mask=self.causal_mask)\n",
        "        else:\n",
        "            # compute attention scores (\"affinities\")\n",
        "            wei = q @ k.transpose(-2,-1) # (B, H, 1, C/H) @ (B, H, C/H, T) -> (B, H, 1, T)\n",
        "            wei = wei * self.head_size ** -0.5 # scaled attention\n",
        "            wei = wei.masked_fill(self.tril[T_k-T:T_k, T_k-T:T_k] == 0, float('-inf')) # (B, T, T)\n",
        "            wei = F.softmax(wei, dim=-1) # (B, H, T, T)\n",
        "            # apply attention to values\n",
        "            out = wei @ v # (B, H, 1, T) @ (B, H, T, C/H) -> (B, H, 1, C/H)\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C) # (B, H, T, C/H) -> (B, T, H, C/H) -> (B, T, C)\n",
        "        out = self.o(out)\n",
        "        return out, kv_cache\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(config)\n",
        "        self.ff_layer = FeedForward(config)\n",
        "        self.sa_norm = RMSNorm(config.embed_size)\n",
        "        self.ff_norm = RMSNorm(config.embed_size)\n",
        "    \n",
        "    def forward(self, x, kv_cache=None):\n",
        "        a, kv_cache = self.sa_heads(self.sa_norm(x), kv_cache)\n",
        "        h = x + a\n",
        "        o = h + self.ff_layer(self.ff_norm(h))\n",
        "        return o, kv_cache\n",
        "    \n",
        "class TransformerLM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layer_num = config.layer_num\n",
        "        self.head_num = config.head_num\n",
        "        self.seq_len = config.seq_len\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(config.vocab_size, config.embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from \n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(config.embed_size, config.vocab_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.layer_num)])\n",
        "\n",
        "    def forward(self, idx, targets=None, kv_cache=None):\n",
        "        B, T = idx.shape\n",
        "        _, _, T_past, _ = kv_cache[0][0].shape if kv_cache is not None and kv_cache[0][0] is not None else (0, 0, 0, 0)\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        x = tok_embd\n",
        "        # go through blocks\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x, cache = block(x, None if kv_cache is None else kv_cache[i])\n",
        "            if kv_cache is not None:\n",
        "                kv_cache[i] = cache\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,V)\n",
        "        \n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, V = logits.shape\n",
        "            logits = logits.view(B*T, V)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens, temperature=1, use_cache=True):\n",
        "        if use_cache:\n",
        "            # initialize key-value cache\n",
        "            kv_cache = [(None, None) for _ in range(self.layer_num)]\n",
        "            # idx is (B, T) array of indices in the current context\n",
        "            # crop idx to the last seq_len tokens\n",
        "            idx_context = idx[:, -self.seq_len:]\n",
        "            for _ in range(max_new_tokens):\n",
        "                # get the predictions\n",
        "                logits, loss = self(idx_context, kv_cache=kv_cache)\n",
        "                # focus only on the last time step\n",
        "                logits = logits[:, -1, :] # becomes (B, C)\n",
        "                # apply temperature\n",
        "                logits = logits / temperature if temperature > 0 else logits\n",
        "                # apply softmax to get probabilities\n",
        "                probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "                # sample from the distribution\n",
        "                idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True) # (B, 1)\n",
        "                # append sampled index to the running sequence\n",
        "                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "                # since we have kv cache, only need to pass new token\n",
        "                idx_context = idx_next\n",
        "            return idx\n",
        "        else:\n",
        "            # idx is (B, T) array of indices in the current context\n",
        "            for _ in range(max_new_tokens):\n",
        "                #crop idx to the last seq_len tokens\n",
        "                idx_context = idx[:, -self.seq_len:]\n",
        "                # get the predictions\n",
        "                logits, loss = self(idx_context)\n",
        "                # focus only on the last time step\n",
        "                logits = logits[:, -1, :] # becomes (B, C)\n",
        "                # apply temperature\n",
        "                logits = logits / temperature if temperature > 0 else logits\n",
        "                # apply softmax to get probabilities\n",
        "                probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "                # sample from the distribution\n",
        "                idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True) # (B, 1)\n",
        "                # append sampled index to the running sequence\n",
        "                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "            return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4775511"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test forward pass\n",
        "config = TransformerConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    seq_len=seq_len,\n",
        "    embed_size=256,\n",
        "    head_num=4,\n",
        "    layer_num=6\n",
        ")\n",
        "m = TransformerLM(config)\n",
        "m.to(device)\n",
        "xb, yb = get_batch('train', 5, 1)\n",
        "logits, loss = m(xb, yb)\n",
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fc0ce0180044c668664cc557cb591b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zaydz/.main-venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1713: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final loss: 1.0745582580566406 final val loss: 1.2047595977783203\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# training!\n",
        "model = TransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
        "train(model, optimizer, seq_len, batch_size, total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save\n",
        "torch.save(model.state_dict(), 'models/TransformerLM.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_28159/96251971.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('models/TransformerLM.pt'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): TransformerLM(\n",
              "    (token_embedding_table): Embedding(87, 256)\n",
              "    (lm_head): Linear(in_features=256, out_features=87, bias=True)\n",
              "    (blocks): ModuleList(\n",
              "      (0-5): 6 x Block(\n",
              "        (sa_heads): MultiHeadAttention(\n",
              "          (key): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (query): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (value): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (ff_layer): FeedForward(\n",
              "          (lin_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (lin_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (sa_norm): RMSNorm()\n",
              "        (ff_norm): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load model\n",
        "model = TransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.load_state_dict(torch.load('models/TransformerLM.pt'))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1e6d09745c645cab97ce2a92133cf0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "perplexity: 3.334986925125122 loss: 1.20446875\n"
          ]
        }
      ],
      "source": [
        "# calculate perplexity\n",
        "ppl, loss = perplexity(model, seq_len, seq_len)\n",
        "print(\"perplexity:\", ppl, \"loss:\", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00r0pbm3b5eX",
        "outputId": "bdd3b34e-32a0-4724-b528-c162c0fd0c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[53, 72, 78,  1, 80, 66, 69, 69,  1, 71, 62, 79, 62, 75]])\n",
            "You will never decide what to do if you will take to see me.\n",
            "\n",
            "I don't mind it.\n",
            "\n",
            "I wonder if it'll be to make it to the bunny today.\n",
            "\n",
            "I wonder if that happens at all.\n",
            "\n",
            "If I can continue fighting something that would be the memories of the moment.\n",
            "\n",
            "But it doesn't matter if I heard that.\n",
            "\n",
            "I don't want to hear that for you.\n",
            "\n",
            "I wonder if I can become this possible.\n",
            "\n",
            "I'm sure that I would like to hear you.\n",
            "\n",
            "I wonder if the things would look like this...\n",
            "\n",
            "I think it's the only one who continues to take a picture of him.\n",
            "\n",
            "Where's he going home?\n",
            "\n",
            "If that's the worst true power to continue the entire training companies,\n",
            "\n",
            "I would have come to the train somewhere seriously.\n",
            "\n",
            "What do you think there are someone who can come to the country of the world line before we met.\n",
            "\n",
            "The next step is the power of the country with the moment I came to the prize again.\n",
            "\n",
            "I am the super bad and she could say that.\n",
            "\n",
            "I can explode the world from the fact that she couldn't make it to the manga she was a man for a manner.\n",
            "\n",
            "I'm a go\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "idx = encode(\"You will never\")\n",
        "print(torch.tensor([idx]))\n",
        "print(decode(model.generate(idx=torch.tensor([idx], dtype=torch.long).to(device), max_new_tokens=1000, temperature=0.5, use_cache=True)[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".main-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
